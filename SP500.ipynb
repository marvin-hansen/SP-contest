{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SP500.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marvin-hansen/SP-contest/blob/master/SP500.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "N9BY2HSkXVRe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Install requirements"
      ]
    },
    {
      "metadata": {
        "id": "fUbOyRkdXOqg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# set correct version\n",
        "!pip install imgaug==0.2.7 \n",
        "\n",
        "# update pandas \n",
        "!pip install --upgrade pandas \n",
        "\n",
        "# update numpy \n",
        "!pip install --upgrade numpy \n",
        "\n",
        "# updated fast.ai to latest \n",
        "!pip install --upgrade fastai\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "glCJS0DfX-Jt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Restart runtime"
      ]
    },
    {
      "metadata": {
        "id": "Hr-ilLbHYH2U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ]
    },
    {
      "metadata": {
        "id": "UHPt9MkIXgvq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import platform\n",
        "import warnings\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import datetime, DataFrame\n",
        "from pandas.io.parsers import TextFileReader\n",
        "\n",
        "# File & io\n",
        "from enum import Enum, unique\n",
        "from pathlib import Path\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "# fast ai \n",
        "import fastai\n",
        "from fastai import *\n",
        "from fastai.imports import *\n",
        "from fastai.basics import *\n",
        "from fastai.tabular import *\n",
        "from fastai.metrics import *\n",
        "\n",
        "import torch\n",
        "print(\"Done\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wjYFBuO0YJyz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"* Python Version: \" + str(platform.python_version()))\n",
        "print(\"* Pandas Version: \" + str(pd.__version__))\n",
        "print(\"* Numpy Version: \" + str(np.__version__))\n",
        "\n",
        "print(\"* FastAI Version: \" + str(fastai.__version__))\n",
        "print(\"* PyTorch Version: \" + str(torch.__version__))\n",
        "print()\n",
        "!nvcc --version"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xFAbtI0wYRnD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "torch.cuda.current_device()\n",
        "\n",
        "print(\"Cuda available: \" + str(torch.cuda.is_available()))\n",
        "print(\"Cuda enabled:\" + str(torch.backends.cudnn.enabled))\n",
        "\n",
        "#https://stackoverflow.com/questions/48152674/how-to-check-if-pytorch-is-using-the-gpu\n",
        "# setting device on GPU if available, else CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n",
        "print()\n",
        "\n",
        "\n",
        "#Additional Info when using cuda\n",
        "if device.type == 'cuda':\n",
        "    print(\"GPU used: \" + torch.cuda.get_device_name(0))\n",
        "    print('Memory Usage:')\n",
        "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
        "    print('Cached:   ', round(torch.cuda.memory_cached(0)/1024**3,1), 'GB')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_H9wVwonZACl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tools "
      ]
    },
    {
      "metadata": {
        "id": "Zxovc9ovYdaL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## file utils\n",
        "@unique\n",
        "class Data(Enum):\n",
        "    SP500_50Y_RAW = 0\n",
        "    SP500_90Y_RAW = 1\n",
        "    SP500_ALL = 2\n",
        "    SP500_TRAIN = 3\n",
        "    SP500_TEST = 4\n",
        "    SP500_VALID = 5\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5V1szX1RZLKW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_path(data_name: Data, url: bool):\n",
        "    \"\"\"\n",
        "    Returns the path corresponding to the data set specified in the enum Data.\n",
        "    Note, the enum is @unique so no two datasets can have the same path.\n",
        "\n",
        "    ONLY \"raw\" data have web url's to download the official reference dataset.\n",
        "    train, test, validate, and all are generated files.\n",
        "\n",
        "    When URL = True, the corresponding web url for the data set will be returned.\n",
        "\n",
        "    By default, path is relative /Data/filename.end\n",
        "\n",
        "    Update data_folder to set a different path.\n",
        "\n",
        "    :param data_name: Enum - Dataset\n",
        "    :param url: bool flag to indicate whether to return a local path or a web url\n",
        "    :return: file path or url\n",
        "    \"\"\"\n",
        "\n",
        "    data_folder = \"\" #\"Data/\"\n",
        "    sp_name = \"SP500\"\n",
        "    sp50_name = \"SP500-50Y\"\n",
        "    sp90_name = \"SP500-90Y\"\n",
        "    frmt = \".csv\"\n",
        "\n",
        "    path = \"\"\n",
        "\n",
        "    if (data_name is Data.SP500_50Y_RAW):\n",
        "        path = data_folder + sp50_name + \"-raw\" + frmt\n",
        "        if (url):\n",
        "            u = \"https://raw.githubusercontent.com/marvin-hansen/SP-contest/master/Data/SP500-50Y-raw.csv\"\n",
        "            path = requests.get(u).content\n",
        "\n",
        "    if (data_name is Data.SP500_90Y_RAW):\n",
        "        path = data_folder + sp90_name + \"-raw\" + frmt\n",
        "        if (url):\n",
        "            u = \"https://raw.githubusercontent.com/marvin-hansen/SP-contest/master/Data/SP500-90Y-raw.csv\"\n",
        "            path = requests.get(u).content\n",
        "\n",
        "\n",
        "    if (data_name is Data.SP500_ALL):\n",
        "        path = data_folder + sp_name + \"-all\" + frmt\n",
        "        if (url):\n",
        "            u = \"\"\n",
        "            path = requests.get(u).content\n",
        "    if (data_name is Data.SP500_TRAIN):\n",
        "        path = data_folder + sp_name + \"-train\" + frmt\n",
        "        if (url): path = \"\"\n",
        "    if (data_name is Data.SP500_TEST):\n",
        "        path = data_folder + sp_name + \"-test\" + frmt\n",
        "        if (url): path = \"\"\n",
        "    if (data_name is Data.SP500_VALID):\n",
        "        path = data_folder + sp_name + \"-valid\" + frmt\n",
        "        if (url): path = \"\"\n",
        "\n",
        "    return path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f21JjiHWZL2b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_csv_file(data_name: Data, url: bool):\n",
        "    \"\"\" loads the S&P 500 index file from the path in the path function\n",
        "    :param path:\n",
        "    :return: pandas data frame\n",
        "    \"\"\"\n",
        "    if url:\n",
        "        return pd.read_csv(io.StringIO(get_path(data_name=data_name, url=url).decode('utf-8')),infer_datetime_format=True)\n",
        "\n",
        "    else:\n",
        "        return pd.read_csv(get_path(data_name=data_name, url=url), infer_datetime_format=True, index_col=\"Date\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KaODdAWvZjTt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_data(data: Data, force_download: bool = False):\n",
        "    \"\"\" Loads the requested dataset, either from the web or from a local copy.\n",
        "    @depends: Data - Enum that specifies available datasets\n",
        "    @depends: get_path Adjust local file path and URL's.\n",
        "    Default relative path is data/\n",
        "    Default  URL is public github repo.\n",
        "    \n",
        "    :param data: dataset to load\n",
        "    :param force_download: Download the web-version and override local copy. FALSE by default.\n",
        "    :return: pandas dataframe\n",
        "    \"\"\"\n",
        "    path = Path(get_path(data_name=data, url=False))\n",
        "    if(force_download or path.exists()== False):\n",
        "        print(\"Load from URL\")\n",
        "        df = load_csv_file(data_name=data, url=True)\n",
        "        # ... store a local copy to accelerate the next data loading\n",
        "        #df.to_csv(get_path(data_name=data, url=False))\n",
        "        return df\n",
        "    else: # local copy must be there b/c path exists\n",
        "        # load\n",
        "        print(\"Load data from local  file\")\n",
        "        return load_csv_file(data_name=data, url=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nWX0evCBc66E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def save_train_test_valid(df: DataFrame, split_ratio: float, valid_size: int, verbose: bool):\n",
        "    \"\"\"\n",
        "    splits a dataframe into train, test, and validation and stores each set in a different file\n",
        "    :param df: pandas data frame\n",
        "    :param split_ratio: ratio between train & split\n",
        "    :param valid_size: number of rows in the validation set\n",
        "    :param verbose: prints out file paths when set to true\n",
        "    :return: void\n",
        "    \"\"\"\n",
        "    if (verbose):\n",
        "        print(\"Save data to file.. \")\n",
        "    \n",
        "    # replace NaN with zero\n",
        "    df = df.fillna(0)\n",
        "    \n",
        "    \n",
        "    # store validation set as the latest of n data points\n",
        "    if(valid_size > 0):\n",
        "      valid = df.head(valid_size)\n",
        "      valid_file = get_path(data_name=Data.SP500_VALID, url=False)\n",
        "      valid.to_csv(valid_file)\n",
        " \n",
        "    # split remaining data into train & test sets\n",
        "    split = int(len(df) * split_ratio)\n",
        "    train = df[0:split]  #\n",
        "    test = df[split:len(df)]\n",
        "  \n",
        "    ## store train dataset\n",
        "    train_file = get_path(data_name=Data.SP500_TRAIN, url=False)\n",
        "    train.to_csv(train_file)\n",
        "\n",
        "    # store train\n",
        "    test_file = get_path(data_name=Data.SP500_TEST, url=False)\n",
        "    test.to_csv(test_file)\n",
        "\n",
        "    if (verbose):\n",
        "        print()\n",
        "        print('All data : %d' % (len(df)))\n",
        "        print('Training data: %d' % (len(train)))\n",
        "        print('Testing data: %d' % (len(test)))\n",
        "        if(valid_size > 0):\n",
        "          print('Validation data: %d' % (len(valid)))\n",
        "        print()\n",
        "        print(\"Stored train data in file: \")\n",
        "        print(train_file)\n",
        "        print()\n",
        "        print(\"Stored train data in file: \")\n",
        "        print(test_file)\n",
        "        if(valid_size > 0):\n",
        "          print()\n",
        "          print(\"Stored validation data in file: \")\n",
        "          print(valid_file)\n",
        "        print()\n",
        "        print(\"Done! All data are saved\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rUDXer03kxwz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def drop_feature(df, col_name):\n",
        "    \"\"\"\n",
        "    Drops the given column(s) on the given data frame\n",
        "    \"\"\"\n",
        "    return df.drop(columns=col_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D-Y2_2vxb6bv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load, split & save  data to train & test "
      ]
    },
    {
      "metadata": {
        "id": "w7KEViJxZm2U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "verbose = False\n",
        "\n",
        "df = load_data(data=Data.SP500_50Y_RAW, force_download=True)\n",
        "print(\"Load raw data: Done!\")\n",
        "\n",
        "# Close and Adj. Close have about the same values, thus adj. close isn't needed \n",
        "df =  drop_feature(df, \"Adj Close\")\n",
        "print(\"Remove feature Adj Close: Done!\")\n",
        "\n",
        "# That's required to categorify date \n",
        "df['Date'] = pd.to_datetime(df['Date'], infer_datetime_format=True)\n",
        "print(\"Convert Date to datetime: Done!\")\n",
        "\n",
        "# That's required to capture trends, seasonality, and time patterns in the dataset. \n",
        "add_datepart(df, \"Date\", drop=False)\n",
        "print(\"Categorify Date: Done!\")\n",
        "\n",
        "if (verbose):\n",
        "    print(\"Inspect Data: \")\n",
        "    print(df.info())\n",
        "    print()\n",
        "    print(df.tail(3).T)    \n",
        "    \n",
        "split = 0.80 # for a 80/20 split\n",
        "valid_size = 30  # last month for validation. Set to zero for no validation data \n",
        "\n",
        "print(\"Done:Split into Train & Test \")\n",
        "save_train_test_valid(df=df, split_ratio=split, valid_size=valid_size, verbose=True)##"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mKcrcBAqg6iV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load train & test set"
      ]
    },
    {
      "metadata": {
        "id": "40t5cg8FdAzE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df = load_data(data=Data.SP500_TRAIN)\n",
        "test_df = load_data(data=Data.SP500_TEST)\n",
        "valid_df = load_data(data=Data.SP500_VALID)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0sccRFWbje66",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# check lenths\n",
        "len(train_df),len(test_df), len(valid_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v6rYfCvPhQPZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(\"Show Train dataset\")\n",
        "train_df.tail(5).T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DgIocXpci02S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_name = 'Close'\n",
        "\n",
        "y_train = train_df[y_name]\n",
        "X_train = drop_feature(train_df, y_name)\n",
        "\n",
        "y_test = train_df[y_name]\n",
        "X_test = drop_feature(test_df, y_name) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AP69Gw8xkEJ_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_test.head().T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1oLrgSvXoDy-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}